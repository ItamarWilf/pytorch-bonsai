[net]
width=128
height=128
in_channels=4

# layer 1
[prunable_conv2d]
out_channels=32
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 2
[prunable_conv2d]
out_channels=32
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 3
[maxpool]
kernel_size=2
stride=2

# layer 4
[prunable_conv2d]
out_channels=64
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 5
[prunable_conv2d]
out_channels=64
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 6
[maxpool]
kernel_size=2
stride=2

# layer 7
[prunable_conv2d]
out_channels=128
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 8
[prunable_conv2d]
out_channels=128
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 9
[maxpool]
kernel_size=2
stride=2

# layer 10
[prunable_conv2d]
out_channels=256
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 11
[prunable_conv2d]
out_channels=256
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 12
[maxpool]
kernel_size=2
stride=2

# layer 13
[prunable_conv2d]
out_channels=512
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 14
[prunable_conv2d]
out_channels=512
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 15
[prunable_deconv2d]
out_channels=256
kernel_size=2
stride=2
padding=0
bias=False

# layer 16
[route]
layers=-5, -1

# layer 17
[prunable_conv2d]
out_channels=256
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 18
[prunable_conv2d]
out_channels=256
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 19
[prunable_deconv2d]
out_channels=128
kernel_size=2
stride=2
padding=0
bias=False

# layer 20
[route]
layers=-12, -1

# layer 21
[prunable_conv2d]
out_channels=128
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 22
[prunable_conv2d]
out_channels=128
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 23
[prunable_deconv2d]
out_channels=64
kernel_size=2
stride=2
padding=0
bias=False

# layer 24
[route]
layers=-19, -1

# layer 25
[prunable_conv2d]
out_channels=64
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 26
[prunable_conv2d]
out_channels=64
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 27
[prunable_deconv2d]
out_channels=32
kernel_size=2
stride=2
padding=0
bias=False

# layer 28
[route]
layers=-26, -1

# layer 29
[prunable_conv2d]
out_channels=32
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 30
[prunable_conv2d]
out_channels=32
kernel_size=3
stride=1
padding=1
bias=True
activation=LeakyReLU
negative_slope=0.2

# layer 31
[prunable_conv2d]
out_channels=4
kernel_size=1
stride=1
padding=0
bias=True

# layer 32
[pixel_shuffle]
upscale_factor=2
output=1

