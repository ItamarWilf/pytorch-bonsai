[net]
height=32
width=32
in_channels=3

#0
[prunable_conv2d]
batch_normalize=0
out_channels=64
kernel_size=3
stride=1
padding=1
activation=ReLU

#1
[prunable_conv2d]
batch_normalize=0
out_channels=64
kernel_size=3
stride=1
padding=1
activation=ReLU

#2
[maxpool]
kernel_size=2
stride=2

#3
[prunable_conv2d]
batch_normalize=0
out_channels=128
kernel_size=3
stride=1
padding=1
activation=ReLU

#4
[prunable_conv2d]
batch_normalize=0
out_channels=128
kernel_size=3
stride=1
padding=1
activation=ReLU

#5
[maxpool]
kernel_size=2
stride=2

#6
[prunable_conv2d]
batch_normalize=0
out_channels=256
kernel_size=3
stride=1
padding=1
activation=ReLU

#7
[prunable_conv2d]
batch_normalize=0
out_channels=256
kernel_size=3
stride=1
padding=1
activation=ReLU

#8
[prunable_conv2d]
batch_normalize=0
out_channels=256
kernel_size=3
stride=1
padding=1
activation=ReLU

#9
[prunable_conv2d]
batch_normalize=0
out_channels=256
kernel_size=3
stride=1
padding=1
activation=ReLU

#10
[maxpool]
kernel_size=2
stride=2

#11
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#12
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#13
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#14
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#15
[maxpool]
kernel_size=2
stride=2

#16
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#17
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#18
[prunable_conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#19
[conv2d]
batch_normalize=0
out_channels=512
kernel_size=3
stride=1
padding=1
activation=ReLU

#20
[maxpool]
kernel_size=2
stride=2

#21
[flatten]

#22
[dropout]

#23
[linear]
out_features=512
activation=ReLU

#24
[dropout]

#25
[linear]
out_features=512
activation=ReLU

#26
[linear]
out_features=10
output=1


